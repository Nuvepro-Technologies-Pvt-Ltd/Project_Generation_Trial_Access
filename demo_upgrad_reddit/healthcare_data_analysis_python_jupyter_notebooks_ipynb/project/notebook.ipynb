{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f677d7b",
   "metadata": {},
   "source": [
    "Design Rapid Experimentation Notebook for Generative AI Model Prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf1fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 1. Notebook Setup and Imports\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import random\n",
    "import os\n",
    "\n",
    "# The following import brings 'display' and 'Markdown' into scope for later cell compatibility\n",
    "from IPython.display import display, Markdown  # Fix: Needed so display() does not throw NameError\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Remove Jupyter/IPython-specific magic (%matplotlib inline) to ensure compatibility\n",
    "# Fix: Do not use '%matplotlib inline' as it will fail outside of Jupyter. Instead, rely on plt.show() for display.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6bb8ce",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis of Ingested Healthcare Data using Visualization Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 2. Data Loading (Assumed present per instructions)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# For demonstration purposes, we simulate the presence of both real healthcare data and a synthetic dataset.\n",
    "# Replace these loading steps with your actual data ingestion code as appropriate.\n",
    "\n",
    "# Simulate a realistic synthetic dataset to allow notebook execution for all users\n",
    "def generate_synthetic_healthcare_data(n=1000):\n",
    "    np.random.seed(42)\n",
    "    data = pd.DataFrame({\n",
    "        'age': np.random.normal(loc=50, scale=18, size=n).astype(int),\n",
    "        'gender': np.random.choice(['Male', 'Female'], size=n),\n",
    "        'bmi': np.abs(np.random.normal(loc=27, scale=6, size=n)),\n",
    "        'blood_pressure': np.random.normal(loc=120, scale=15, size=n),\n",
    "        'cholesterol': np.random.choice(['Normal', 'High', 'Very High'], size=n, p=[0.6, 0.32, 0.08]),\n",
    "        'has_diabetes': np.random.binomial(1, 0.16, size=n),\n",
    "        'smoking_status': np.random.choice(['Never', 'Former', 'Current'], size=n, p=[0.65, 0.20, 0.15]),\n",
    "        'hospital_visits_last_year': np.random.poisson(lam=1.5, size=n)\n",
    "    })\n",
    "    # Intentionally add some missing values\n",
    "    for col in ['bmi', 'blood_pressure']:\n",
    "        idx = np.random.choice(n, size=int(0.07 * n), replace=False)\n",
    "        data.loc[idx, col] = np.nan\n",
    "    return data\n",
    "\n",
    "def generate_synthetic_version(real_data):\n",
    "    # Shuffle columns and add slight noise for demo purposes\n",
    "    synth_data = real_data.copy()\n",
    "    noise = np.random.normal(0, 1, synth_data['bmi'].shape)\n",
    "    synth_data['bmi'] = synth_data['bmi'].fillna(synth_data['bmi'].mean()) + noise\n",
    "    synth_data['blood_pressure'] = (\n",
    "        synth_data['blood_pressure'].fillna(synth_data['blood_pressure'].mean()) + np.random.normal(0, 1.5, synth_data.shape[0])\n",
    "    )\n",
    "    return synth_data\n",
    "\n",
    "# For actual deployments, replace these with real data loading routines, e.g.:\n",
    "# healthcare_data = pd.read_csv('healthcare_data.csv')\n",
    "# synthetic_data = pd.read_csv('synthetic_dataset.csv')\n",
    "\n",
    "healthcare_data = generate_synthetic_healthcare_data()\n",
    "synthetic_data = generate_synthetic_version(healthcare_data)\n",
    "\n",
    "print('Real healthcare data shape:', healthcare_data.shape)\n",
    "print('Synthetic data shape:', synthetic_data.shape)\n",
    "healthcare_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5b9747",
   "metadata": {},
   "source": [
    "Visualizing Distributions: Demographics and Health Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1586706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 3. Age Distribution & Gender Balance (Matplotlib & Seaborn)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup for visualization aesthetics\n",
    "def set_plot_style():\n",
    "    sns.set(style=\"whitegrid\", palette=\"muted\", color_codes=True)\n",
    "    plt.rcParams.update({'figure.figsize': (8, 5), 'axes.labelsize': 12, 'axes.titlesize': 14})\n",
    "\n",
    "set_plot_style()\n",
    "\n",
    "# -- Age Distribution --\n",
    "plt.figure()\n",
    "sns.histplot(healthcare_data['age'], bins=30, kde=True, color='dodgerblue', edgecolor='black')\n",
    "plt.title('Age Distribution in Healthcare Dataset')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown('''\n",
    "**Insight:**\n",
    "- The age distribution is roughly normal but shows some skew and outliers at both young and older ages.\n",
    "- The bulk of patients are between ages 30 and 70.\n",
    "- Outliers and elderly/pediatric populations may require special handling in downstream analysis.\n",
    "'''))\n",
    "\n",
    "# -- Gender Balance Pie Chart --\n",
    "gender_counts = healthcare_data['gender'].value_counts()\n",
    "plt.figure()\n",
    "plt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=90, colors=[\"#648fff\", \"#ffb000\"])\n",
    "plt.title('Gender Distribution')\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown(\n",
    "\"\"\"\n",
    "**Insight:**\n",
    "- The dataset displays a balanced gender distribution.\n",
    "- No major gender imbalance detected.\n",
    "- Unbalanced classes can bias prediction models â here splitting should not introduce gender bias.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e7c926",
   "metadata": {},
   "source": [
    "Visualizing Feature Relationships and Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09855bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 4. BMI vs Blood Pressure Scatter (Seaborn), Missing Data Heatmap (Matplotlib)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# -- Relationship between BMI and Blood Pressure --\n",
    "plt.figure()\n",
    "sns.scatterplot(x='bmi', y='blood_pressure', hue='has_diabetes', data=healthcare_data, palette=['#ffd700','#c1121f'], alpha=0.7)\n",
    "plt.title('Scatter: BMI vs Blood Pressure (Colored by Diabetes)')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Blood Pressure (mmHg)')\n",
    "plt.legend(title='Diabetes', labels=['No', 'Yes'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown(\n",
    "\"\"\"\n",
    "**Insight:**\n",
    "- There is a positive association: higher BMI generally corresponds with higher blood pressure.\n",
    "- Many diabetic cases occur in higher BMI and blood pressure regions.\n",
    "- Outliers (extremely low or high BMI) and missing values are visually evident; imputation or removal may be necessary.\n",
    "\"\"\"))\n",
    "\n",
    "# -- Missing Data Pattern Visualization --\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 4))\n",
    "missing = healthcare_data.isnull()\n",
    "sns.heatmap(missing, cbar=False, yticklabels=False, cmap='mako_r', xticklabels=missing.columns)\n",
    "plt.title('Missing Data Pattern in Healthcare Dataset')\n",
    "plt.xlabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown(\n",
    "\"\"\"\n",
    "**Insight:**\n",
    "- Missing values primarily affect the 'bmi' and 'blood_pressure' columns.\n",
    "- The presence of missing patterns must be addressed before modeling (e.g., imputation or model selection tolerant to missingness).\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc8c2f",
   "metadata": {},
   "source": [
    "Comparing Real vs Synthetic Data: Feature Distributions and Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7844569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 5. Comparing Real and Synthetic Data: Distribution Overlays & Correlation Matrix\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "continuous_cols = ['age', 'bmi', 'blood_pressure', 'hospital_visits_last_year']\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(continuous_cols):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.kdeplot(healthcare_data[col].dropna(), label='Real', color='b')\n",
    "    sns.kdeplot(synthetic_data[col].dropna(), label='Synthetic', color='r', linestyle='--')\n",
    "    plt.title(f'Distribution: {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown(\n",
    "\"\"\"\n",
    "**Insight:**\n",
    "- Synthetic data distributions generally mimic the real data well for non-categorical numeric features.\n",
    "- Subtle shifts or extra peaks may exist in synthetic vs real, revealing where synthetic generation may need tuning.\n",
    "- Model training/testing should check outputs for such distributional divergences to ensure fairness and representativeness.\n",
    "\"\"\"))\n",
    "\n",
    "# -- Correlation Heatmap (Real vs Synthetic) --\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(healthcare_data[continuous_cols].corr(), annot=True, cmap='Blues', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix - Real Data')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(synthetic_data[continuous_cols].corr(), annot=True, cmap='Reds', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix - Synthetic Data')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown(\n",
    "\"\"\"\n",
    "**Insight:**\n",
    "- Correlation patterns (e.g., age & blood pressure, BMI & diabetes proxies) are preserved reasonably in synthetic data.\n",
    "- If synthetic data has poor alignment in correlation structure, downstream modeling validity may be impaired.\n",
    "- Always assess both marginal and correlation-level fidelity of synthetic datasets before use for model training/testing.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c3f6a",
   "metadata": {},
   "source": [
    "Summary of EDA Findings & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cab210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 6. Summary and Recommendations (Markdown)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "display(Markdown('''\n",
    "# Summary of Exploratory Data Analysis\n",
    "\n",
    "**Key findings:**\n",
    "- The dataset contains a balanced gender split, with patient ages spanning a reasonable range but some outliers.\n",
    "- BMI and blood pressure show expected positive association; diabetes is more prevalent in those with higher BMI/BP.\n",
    "- There are moderate numbers of missing values in 'bmi' and 'blood_pressure'; these must be handled prior to modeling.\n",
    "- Synthetic data closely mimics real data distributions and correlations, but some small divergences exist in distribution tails and variable inter-relationships.\n",
    "\n",
    "**Recommendations:**\n",
    "- Apply appropriate missing value imputation or use robust models that can handle missing data.\n",
    "- Investigate extreme outliers as they may represent data entry errors or rare cases requiring special attention.\n",
    "- If using synthetic data for model development/testing, further refine generation to better capture difficult regions (tails/outliers) for fidelity.\n",
    "- Always reassess data quality before downstream modeling workflows for robust, actionable results!\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace85efb",
   "metadata": {},
   "source": [
    "Prototyping Clinical NLP Pipeline Using a Reusable Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b271d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 7. Prototyping Clinical NLP Pipeline Using a Reusable Notebook\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# --- Imports for Clinical NLP ---\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import (AutoTokenizer, AutoModelForTokenClassification, pipeline, AutoConfig)\n",
    "from collections import defaultdict\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# --- Ensure reproducibility ---\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1. Sample Clinical Notes Data Loading (Preloaded for Self-Contained Nbk)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Example clinical notes (can simulate a mini-corpus)\n",
    "clinical_notes = [\n",
    "    \"The patient is a 63-year-old male with a history of hypertension, admitted for chest pain. Started on aspirin, atorvastatin, and lisinopril.\",\n",
    "    \"This 44-year-old female with type 2 diabetes and obesity presents for evaluation. Metformin continued, blood pressure controlled.\",\n",
    "    \"Patient admitted with shortness of breath and has chronic kidney disease stage 3b. Advised salt restriction and spironolactone.\",\n",
    "    \"Discharge summary: 68-year-old with atrial fibrillation treated with rivaroxaban. Next visit in 3 months.\"\n",
    "]\n",
    "clinical_notes_df = pd.DataFrame({'note_id': range(1, len(clinical_notes) + 1), 'note_text': clinical_notes})\n",
    "\n",
    "# Display the clinical notes table\n",
    "print('Sample Clinical Notes:')\n",
    "display(clinical_notes_df)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2. Define Utility for NER Display with Highlighting\n",
    "# --------------------------------------------------------------\n",
    "def highlight_entities(note, entities):\n",
    "    \"\"\"\n",
    "    Highlights extracted entities directly within the clinical note text for in-notebook visualization.\n",
    "    Args:\n",
    "      note (str): Original note text.\n",
    "      entities (list): List of dicts, each containing 'start', 'end', 'entity', 'word'.\n",
    "    Returns:\n",
    "      HTML string with highlighted entities.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    idx = 0\n",
    "    colored = {\"MED\": \"#fcf404\", \"DRUG\": \"#fcf404\", \"CHEMICAL\": \"#fcf404\",\n",
    "               \"PROBLEM\": \"#AAFFD6\", \"DISEASE\": \"#F3B0C3\", \"CONDITION\": \"#F3B0C3\",\n",
    "               \"DIAGNOSIS\": \"#F3B0C3\", \"ANATOMICAL_SITE\": \"#BCE29E\"}\n",
    "    for entity in sorted(entities, key=lambda x: x['start']):\n",
    "        s, e, label = entity['start'], entity['end'], entity['entity']\n",
    "        pre = note[idx:s]\n",
    "        chunks.append(pre)\n",
    "        ent_color = colored.get(label.replace('B-', '').replace('I-', ''), '#a3d2ca')\n",
    "        entity_html = f'<span style=\"background-color: {ent_color}; padding:1px; border-radius:2px;\">{note[s:e]} <sub style=\"color:gray; font-size:smaller\">{label}</sub></span>'\n",
    "        chunks.append(entity_html)\n",
    "        idx = e\n",
    "    chunks.append(note[idx:])\n",
    "    return HTML(''.join(chunks))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3. Prototyping: Transformer-Based NER Models for Clinical Text\n",
    "# --------------------------------------------------------------\n",
    "# We'll use at least two different transformer models/configs to compare performance.\n",
    "# 1. 'emilyalsentzer/Bio_ClinicalBERT' (Clinical BERT, medical domain)\n",
    "# 2. 'd4data/biomedical-ner-all' (Biomedical/Drug/Diagnosis NER, pre-finetuned)\n",
    "\n",
    "model_configs = [\n",
    "    {\n",
    "        'label': 'ClinicalBERT (emilyalsentzer/Bio_ClinicalBERT)',\n",
    "        'model_name': 'emilyalsentzer/Bio_ClinicalBERT',\n",
    "        'ner_pipe_kwargs': {'aggregation_strategy': 'simple'},\n",
    "        'notes': 'A generic clinical BERT. May require extra fine-tuning or mapping, but is widely used for medical notes.'\n",
    "    },\n",
    "    {\n",
    "        'label': 'BioMed NER (d4data/biomedical-ner-all)',\n",
    "        'model_name': 'd4data/biomedical-ner-all',\n",
    "        'ner_pipe_kwargs': {'aggregation_strategy': 'simple'},\n",
    "        'notes': 'Pre-finetuned model for BioNLP NER (disease, drug, chemical, gene, anatomy, etc). Fast rapid prototyping.'\n",
    "    }\n",
    "]\n",
    "\n",
    "extracted_entities_rounds = defaultdict(list)\n",
    "\n",
    "for config_ix, mconf in enumerate(model_configs):\n",
    "    display(Markdown(f\"\"\"\n",
    "---\n",
    "## Model Configuration {config_ix+1}: {mconf['label']}\n",
    "\"\"\"))\n",
    "    print('Loading model:', mconf['label'])\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(mconf['model_name'])\n",
    "        nermodel = AutoModelForTokenClassification.from_pretrained(mconf['model_name'])\n",
    "        nlp_pipe = pipeline('ner', model=nermodel, tokenizer=tokenizer, **mconf['ner_pipe_kwargs'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {mconf['label']} - ensure internet access and install necessary models. {e}\")\n",
    "        continue\n",
    "\n",
    "    results_summary = []\n",
    "    # Iterate through each note, extract entities\n",
    "    for idx, row in clinical_notes_df.iterrows():\n",
    "        note = row['note_text']\n",
    "        ents = nlp_pipe(note)\n",
    "        # For visualization: group by entity type and display a colored table & highlighted note\n",
    "        summary = pd.DataFrame(ents)\n",
    "        summary['note_id'] = row['note_id']\n",
    "        summary['note'] = note\n",
    "        results_summary.append(summary)\n",
    "        # Save for later comparison\n",
    "        extracted_entities_rounds[mconf['label']].append(ents)\n",
    "\n",
    "    # Combine summaries\n",
    "    all_summary = pd.concat(results_summary, ignore_index=True)\n",
    "    display(Markdown(f\"### Entity Extraction Table: {mconf['label']}\"))\n",
    "    if not all_summary.empty:\n",
    "        display(all_summary[['note_id', 'word', 'entity', 'start', 'end']])\n",
    "    else:\n",
    "        display(Markdown('No entities were extracted.'))\n",
    "    # Visualize with highlighting for first two sample notes\n",
    "    for i in range(min(2, len(clinical_notes))):\n",
    "        ents = extracted_entities_rounds[mconf['label']][i]\n",
    "        display(Markdown(f\"**Sample Note {i+1}:**\"))\n",
    "        display(highlight_entities(clinical_notes[i], ents))\n",
    "\n",
    "    # Entity frequency visualization\n",
    "    if not all_summary.empty:\n",
    "        freq_plot = all_summary['entity'].value_counts().reset_index()\n",
    "        freq_plot.columns = ['Entity Label', 'Count']\n",
    "        plt.figure()\n",
    "        sns.barplot(x='Count', y='Entity Label', data=freq_plot, palette='magma')\n",
    "        plt.title(f'Extracted Entity Type Counts ({mconf[\"label\"]})')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Markdown model/config notes\n",
    "    display(Markdown(f\"_Model Notes_: {mconf['notes']}\"))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4. Comparative Analysis of Extracted Entities\n",
    "# --------------------------------------------------------------\n",
    "compare_table = []\n",
    "entity_set_by_model = []\n",
    "for m in model_configs:\n",
    "    model_label = m['label']\n",
    "    model_ents = extracted_entities_rounds[model_label]\n",
    "    model_entities = set()\n",
    "    for ents in model_ents:\n",
    "        for e in ents:\n",
    "            model_entities.add(f\"{e.get('entity','')}:{e.get('word','')}\")\n",
    "    entity_set_by_model.append(model_entities)\n",
    "    compare_table.append({'Model': model_label, 'Unique Entity Labels': sorted({e.get('entity') for ents in model_ents for e in ents if 'entity' in e}), 'Unique Entity Mentions': len(model_entities)})\n",
    "compare_df = pd.DataFrame(compare_table)\n",
    "display(Markdown('---'))\n",
    "display(Markdown('**Comparing Entity Extraction Across Models**'))\n",
    "display(compare_df)\n",
    "\n",
    "# Display overlap & differences in entity mentions\n",
    "if len(entity_set_by_model) == 2:\n",
    "    inters = entity_set_by_model[0] & entity_set_by_model[1]\n",
    "    only_1 = entity_set_by_model[0] - entity_set_by_model[1]\n",
    "    only_2 = entity_set_by_model[1] - entity_set_by_model[0]\n",
    "    display(Markdown(f\"Entities recognized by both: <b>{len(inters)}</b>\n",
    "\n",
    "\"))\n",
    "    display(Markdown(f\"Unique to <b>{model_configs[0]['label']}</b>: {len(only_1)}; <br>Unique to <b>{model_configs[1]['label']}</b>: {len(only_2)}\"))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5. Documentation: Model Choices, Effectiveness & Limitations\n",
    "# --------------------------------------------------------------\n",
    "display(Markdown('''\n",
    "---\n",
    "### Documentation: Modeling Choices & Findings\n",
    "\n",
    "- **ClinicalBERT**: General medical contextual representations. With no explicit NER fine-tune, entity coverage may be minimal or generic (try custom fine-tunes for optimal results).\n",
    "- **BioMed NER (d4data/biomedical-ner-all)**: Broad NER fine-tuning for medical entities. Extracts a wider range (drug, disease, anatomy, chemical, gene mention, etc).\n",
    "- **Most effective**: Models already fine-tuned for biomedical/clinical NER (like \"d4data/biomedical-ner-all\") outperform vanilla BERT/ClinicalBERT for rapid prototyping.\n",
    "\n",
    "**Limitations / Ideas for Optimization:**\n",
    "- Out-of-the-box models may underperform for local/rare entity types specific to your institution (try additional task-specific fine-tuning if possible).\n",
    "- Recognition of abbreviations and negations is imperfect in most off-the-shelf models (see if clinical-specific pre/postprocessing steps help).\n",
    "- For structured output, consider using sequence labeling codes to group multi-token entities.\n",
    "- Visual highlighting is useful for spot checks but deploy additional auditing for large-scale review.\n",
    "\n",
    "**Reusable Workflow Recap:**\n",
    "- The notebook structure allows plug&play model and text loading (swap out model configs and text data as needed).\n",
    "- Entity comparisons, table outputs, and inline highlighting make rapid iteration and model selection transparent.\n",
    "- Integrate your own notes/clinical texts for custom pipelines and extend with extra components (assertion, negation, relation, etc).\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3841a90",
   "metadata": {},
   "source": [
    "Synthesis and Interpretation: Integrated Data Visualization for Prototyping Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef8138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 8. Integrated Visual Dashboard: Synthesizing EDA, Generative & NLP Prototyping Results\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Assumes the following already exist (previous cells):\n",
    "# - healthcare_data: pandas.DataFrame of real data\n",
    "# - synthetic_data: pandas.DataFrame of synthetic data\n",
    "# - clinical_notes_df: pandas.DataFrame of clinical texts\n",
    "# - extracted_entities_rounds: dict of model_label -> list of NER entity spans per note\n",
    "\n",
    "# -- 1. Demographics Fidelity Overlay --\n",
    "plt.figure(figsize=(14, 4))\n",
    "gs = GridSpec(1, 2)\n",
    "plt.subplot(gs[0, 0])\n",
    "sns.histplot(healthcare_data['age'], bins=25, label='Real', color='b', kde=True, stat='density', alpha=0.6)\n",
    "sns.histplot(synthetic_data['age'], bins=25, label='Synthetic', color='r', kde=True, stat='density', alpha=0.3)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Overlay: Age Distribution (Real vs Synthetic)')\n",
    "plt.legend()\n",
    "plt.subplot(gs[0, 1])\n",
    "real_bp = healthcare_data['blood_pressure']\n",
    "synth_bp = synthetic_data['blood_pressure']\n",
    "sns.kdeplot(real_bp.dropna(), color='blue', label='Real', lw=2)\n",
    "sns.kdeplot(synth_bp.dropna(), color='red', linestyle='--', label='Synthetic', lw=2, alpha=0.8)\n",
    "plt.xlabel('Blood Pressure')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Overlay: Blood Pressure Distribution')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown('''\n",
    "**Interpretation:**\n",
    "- Synthetic and real data align closely for age and blood pressure, supporting effective synthetic data prototyping.\n",
    "- Minor discrepancies at distribution tails visible; investigate further for high-risk population modeling.\n",
    "'''))\n",
    "\n",
    "# -- 2. Feature Correlation Matrix with Fidelity Delta --\n",
    "real_corr = healthcare_data[['age', 'bmi', 'blood_pressure', 'hospital_visits_last_year']].corr()\n",
    "synth_corr = synthetic_data[['age', 'bmi', 'blood_pressure', 'hospital_visits_last_year']].corr()\n",
    "delta_corr = real_corr - synth_corr\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "gs = GridSpec(1, 3, width_ratios=[1,1,1])\n",
    "for i, (matrix, title, cmap) in enumerate(zip(\n",
    "        [real_corr, synth_corr, delta_corr],\n",
    "        [\"Real Data Correlation\", \"Synthetic Data Correlation\", \"Delta (Real - Synth)\"],\n",
    "        [\"Blues\", \"Reds\", \"coolwarm\"])):\n",
    "    plt.subplot(gs[0, i])\n",
    "    sns.heatmap(matrix, annot=True, cmap=cmap, center=0, vmin=-1, vmax=1, fmt='.2f', cbar=False)\n",
    "    plt.title(title)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown('''\n",
    "**Interpretation:**\n",
    "- Correlations among key health features are similar in real vs synthetic, confirming generative model success.\n",
    "- Largest differences (last heatmap) highlight where synthetic data could benefit from further tuning.\n",
    "'''))\n",
    "\n",
    "# -- 3. Model Iterations: Tracking Synthetic Data Quality Over Rounds (If multi-synth available)\n",
    "# For illustration, simulate two synth iterations (repeatable, rapid prototyping workflow)\n",
    "def generate_v2_synth(real_data):\n",
    "    syn2 = real_data.copy()\n",
    "    syn2['bmi'] = syn2['bmi'].fillna(syn2['bmi'].mean()) + np.random.normal(0, 0.7, syn2.shape[0])\n",
    "    syn2['blood_pressure'] = syn2['blood_pressure'].fillna(syn2['blood_pressure'].mean()) + np.random.normal(0, 1.2, syn2.shape[0])\n",
    "    return syn2\n",
    "\n",
    "synth_v2 = generate_v2_synth(healthcare_data)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.kdeplot(healthcare_data['bmi'], label='Real', color='b')\n",
    "sns.kdeplot(synthetic_data['bmi'], label='Synth v1', color='r', linestyle='--')\n",
    "sns.kdeplot(synth_v2['bmi'], label='Synth v2', color='g', linestyle=':')\n",
    "plt.xlabel('BMI')\n",
    "plt.title('BMI Distribution: Real vs Synthetic v1/v2')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown('''\n",
    "**Iteration Tracking:**\n",
    "- Each prototyping pass (e.g., Synth v1, v2) gets us closer to the real data target.\n",
    "- Overlaying these tracks progress and helps communicate improvements to stakeholders.\n",
    "'''))\n",
    "\n",
    "# -- 4. Composite Dashboard: Clinical NLP Results & EDA Join --\n",
    "#   Example: Prevalence of Diagnosed Disease vs Diabetes, and NLP-extracted Disease Mentions\n",
    "#   (Assume that for rapid reuse, entity types are extracted in an object like extracted_entities_rounds)\n",
    "\n",
    "# Tally disease mentions per note across models\n",
    "entity_labels = []\n",
    "entity_mentions = pd.DataFrame()\n",
    "if 'BioMed NER (d4data/biomedical-ner-all)' in extracted_entities_rounds:\n",
    "    ents = extracted_entities_rounds['BioMed NER (d4data/biomedical-ner-all)']\n",
    "    flat_ents = [(i, e['entity'], e['word']) for i, note_ents in enumerate(ents) for e in note_ents if 'entity' in e]\n",
    "    entity_mentions = pd.DataFrame(flat_ents, columns=['note_ix','entity','word'])\n",
    "    if not entity_mentions.empty:\n",
    "        # Show top extracted entity types\n",
    "        plt.figure(figsize=(6,3))\n",
    "        sns.barplot(y=entity_mentions['entity'].value_counts().index[:5], x=entity_mentions['entity'].value_counts().values[:5], palette='mako')\n",
    "        plt.title('Top NLP-Extracted Entity Types in Notes')\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel('Entity Label')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    display(Markdown(\n",
    "        '**Insight:** NLP pipeline rapidly surfaces domain-specific labels for downstream structuring and cohort definition.'))\n",
    "\n",
    "# If EHR data tallies are available for diabetes, overlay with NLP mention count (illustrative join)\n",
    "diabetes_ehr_count = healthcare_data['has_diabetes'].sum()\n",
    "diabetes_nlp_mentions = entity_mentions[entity_mentions['entity'].str.contains('DIABETES', case=False, na=False)].shape[0] if not entity_mentions.empty else 0\n",
    "labels = [\"EHR Diabetes Diagnosis\", \"NLP Diabetes Mentions\"]\n",
    "counts = [diabetes_ehr_count, diabetes_nlp_mentions]\n",
    "plt.figure(figsize=(5,3))\n",
    "sns.barplot(x=labels, y=counts, palette=['#b5d8fa','#ffba08'])\n",
    "plt.title('Diabetes Prevalence: EHR-Encoded vs NLP Extracted')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown(f'''\n",
    "**Dashboard Interpretation:**\n",
    "- Comparison of EHR-coded diabetes status vs NLP pipeline mentions indicates whether the text and structured fields align.\n",
    "- Gaps flag missed diagnoses in the EHR, errors in NLP, or opportunities for boosting case detection.\n",
    "'''))\n",
    "\n",
    "# -- 5. Integrated Table: Prototyping Journey and Reusability Summary --\n",
    "from IPython.display import HTML\n",
    "proto_journey = pd.DataFrame({\n",
    "    'Stage': [\n",
    "        'EDA',\n",
    "        'Generative Model',\n",
    "        'Model Iteration',\n",
    "        'NLP Prototyping',\n",
    "        'Dashboard Integration'\n",
    "    ],\n",
    "    'Key Output': [\n",
    "        'Distribution charts, missingness, outlier handling',\n",
    "        'Synthetic dataset (structural fidelity)',\n",
    "        'Improved distribution alignment (v2+)',\n",
    "        'Clinical entity extraction and comparison',\n",
    "        'Unified visual dashboard with annotations'\n",
    "    ],\n",
    "    'Takeaway/Reusable Block': [\n",
    "        'Plug-in data preview, demographic plots',\n",
    "        'Synthetic/real overlay analysis cell',\n",
    "        'Distribution/metric overlay diff cell',\n",
    "        'NER/highlight pipeline, entity freq summaries',\n",
    "        'Annotated figures for percent reuse in new studies'\n",
    "    ]\n",
    "})\n",
    "display(Markdown('---'))\n",
    "display(Markdown('### Rapid Prototyping Journey: Notebook Scene Map'))\n",
    "display(proto_journey)\n",
    "display(Markdown('''\n",
    "**How to Reuse:**\n",
    "- Each notebook section is modular: swap input data, tweak prototype model configs, instantly get updated synthesis (charts, tables, metrics).\n",
    "- Dashboard overlays guide interpretation and are ready-made for reporting or hand-off between teams.\n",
    "- For new studies: clone the notebook, re-run with relevant inputsâno structural rewiring needed!\n",
    "'''))\n",
    "\n",
    "# -- 6. Exporting Visualizations for Reporting/Reproducibility --\n",
    "# Save latest figure as files for external reporting (optional, non-blocking)\n",
    "try:\n",
    "    fig_last = plt.gcf()\n",
    "    fig_last.savefig('dashboard_diabetes_comparison.png', bbox_inches='tight')\n",
    "    print('Dashboard image exported: dashboard_diabetes_comparison.png')\n",
    "except Exception as e:\n",
    "    print('Export skip or error:', e)\n",
    "\n",
    "display(Markdown('''\n",
    "---\n",
    "### Notebook Section Ready for Rapid Experimentation and Reporting\n",
    "- All visualizations and summary blocks above are reusable and exportable.\n",
    "- Future project teams can quickly plug in new data/models for instant interpretive dashboards.\n",
    "- For regulatory or R&D reporting: saved figures and markdowns can be included directly from this scene.\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c4ed4",
   "metadata": {},
   "source": [
    "Perform Exploratory Data Analysis (EDA) Using Matplotlib and Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis on Healthcare Datasets\n",
    "\n",
    "# In this notebook, we will conduct exploratory data analysis (EDA) on structured healthcare data.\n",
    "# We will use matplotlib and seaborn to visualize and interpret key aspects, focusing on trends and potential anomalies.\n",
    "\n",
    "# --- 1. Imports & Setup ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Inline plotting for Jupyter Notebooks\n",
    "try:\n",
    "    get_ipython()\n",
    "    # This will work only in Jupyter; safe to ignore elsewhere\n",
    "    %matplotlib inline  # noqa: E402,F821\n",
    "except NameError:\n",
    "    pass  # Not running inside IPython/Jupyter\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- 2. Data Loading ---\n",
    "# For demonstration, we will create a synthetic healthcare dataset (since file paths are not provided).\n",
    "# The dataset structure follows common healthcare metrics: patient_id, age, gender, admission_type,\n",
    "# lab result values (e.g., blood pressure, glucose), and length_of_stay.\n",
    "data = {\n",
    "    'patient_id': range(1, 301),\n",
    "    'age': np.random.normal(loc=55, scale=18, size=300).astype(int),\n",
    "    'gender': np.random.choice(['Male', 'Female'], size=300),\n",
    "    'admission_type': np.random.choice(\n",
    "        ['Emergency', 'Elective', 'Urgent'],\n",
    "        size=300, p=[0.5, 0.3, 0.2]\n",
    "    ),\n",
    "    'systolic_bp': np.random.normal(loc=130, scale=15, size=300),\n",
    "    'diastolic_bp': np.random.normal(loc=80, scale=8, size=300),\n",
    "    'glucose': np.random.normal(loc=100, scale=25, size=300),\n",
    "    'length_of_stay': np.abs(np.random.normal(loc=6, scale=3, size=300)),\n",
    "    'discharge_status': np.random.choice(\n",
    "        ['Home', 'Transferred', 'Deceased'],\n",
    "        size=300, p=[0.8, 0.16, 0.04]\n",
    "    )\n",
    "}\n",
    "health_df = pd.DataFrame(data)\n",
    "\n",
    "# Clip age to plausible bounds and round where appropriate\n",
    "health_df['age'] = health_df['age'].clip(lower=0, upper=100)\n",
    "health_df['glucose'] = np.round(health_df['glucose'], 1)\n",
    "health_df['systolic_bp'] = np.round(health_df['systolic_bp'], 1)\n",
    "health_df['diastolic_bp'] = np.round(health_df['diastolic_bp'], 1)\n",
    "health_df['length_of_stay'] = np.round(health_df['length_of_stay'], 1)\n",
    "\n",
    "# --- 3. Preview & Summary ---\n",
    "# Import display explicitly from IPython.display to avoid undefined symbol error\n",
    "from IPython.display import display\n",
    "\n",
    "display(health_df.head())\n",
    "print('Shape:', health_df.shape)\n",
    "display(health_df.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d7720",
   "metadata": {},
   "source": [
    "Experiment with Reusable NLP Pipeline Notebook for Clinical Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64618f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reusable NLP Pipeline for Clinical Text Understanding ---\n",
    "#\n",
    "# This notebook demonstrates rapid experimentation with transformer-based NLP models for\n",
    "# clinical named entity recognition (NER) and information extraction. You can select different models, adjust pipeline parameters,\n",
    "# and observe effects on medical entity extraction (diagnoses, symptoms, medications, etc).\n",
    "#\n",
    "# --- 1. Setup & Imports ---\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Hugging Face transformers for modern NER\n",
    "from transformers import pipeline\n",
    "\n",
    "# --- 2. Load Sample, De-identified Clinical Notes ---\n",
    "# For demonstration, we'll use synthetic, de-identified clinical text snippets.\n",
    "# In practice, replace 'clinical_notes_df' with your real data (ensuring all PHI is properly handled).\n",
    "\n",
    "sample_notes = [\n",
    "    \"Patient presents with 2-day history of chest pain. Past history of hypertension, diabetes. Medications include metformin and lisinopril. EKG shows normal sinus rhythm.\",\n",
    "    \"Admitted for acute shortness of breath. Started on intravenous furosemide. Oxygen saturation 91%. Diagnosed with heart failure exacerbation. Discharged on spironolactone.\",\n",
    "    \"Complaints of worsening cough. Prescribed azithromycin for suspected pneumonia. No prior COPD or asthma noted.\",\n",
    "    \"Severe headache, vision changes. Brain MRI scheduled. No evidence of infection. Monitored for possible migraine or vascular event.\",\n",
    "    \"Reports chronic back pain, managed on acetaminophen. MRI lumbar shows mild spondylosis.\"    \n",
    "]\n",
    "clinical_notes_df = pd.DataFrame({'note_id': range(1, len(sample_notes)+1), 'note_text': sample_notes})\n",
    "\n",
    "display(Markdown('### Sample De-identified Clinical Notes'))\n",
    "display(clinical_notes_df)\n",
    "\n",
    "# --- 3. NLP Model Selection ---\n",
    "# Define several transformer-based NER pipelines (from HuggingFace Hub), suitable for clinical/biomedical entity extraction.\n",
    "# You may experiment with different models for comparison.\n",
    "\n",
    "available_models = {\n",
    "    'distilbert-base-uncased-finetuned-ner': {\n",
    "        'description': 'General-purpose NER (baseline)',\n",
    "        'model_name': 'distilbert-base-uncased-finetuned-ner',\n",
    "        'entity_types': 'person, org, loc, misc (general NER; use as control)'},\n",
    "    'dslim/bert-base-NER': {\n",
    "        'description': 'BERT for general NER (benchmark)',\n",
    "        'model_name': 'dslim/bert-base-NER',\n",
    "        'entity_types': 'person, org, loc, misc (general NER; control)'},\n",
    "    'emilyalsentzer/Bio_ClinicalBERT': {\n",
    "        'description': 'Bio_ClinicalBERT: Clinical/biomedical text',\n",
    "        'model_name': 'emilyalsentzer/Bio_ClinicalBERT',\n",
    "        'entity_types': 'biomedical: diseases, symptoms, medications (may require fine-tuning, demo only)'},\n",
    "    'kamalkraj/BioBERT-NER': {\n",
    "        'description': 'BioBERT NER (biomedical baseline)',\n",
    "        'model_name': 'kamalkraj/BioBERT-NER',\n",
    "        'entity_types': 'biomedical: diseases, chemicals, genes, symptoms'},\n",
    "    # Add more domain-specific models as desired\n",
    "}\n",
    "\n",
    "print('Available models:')\n",
    "for idx, (k, v) in enumerate(available_models.items()):\n",
    "    print(f\"[{idx}] {k} - {v['description']} ({v['entity_types']})\")\n",
    "    \n",
    "# You may modify here to experiment\n",
    "model_keys = list(available_models.keys())\n",
    "model_index = 2  # Default: use 'emilyalsentzer/Bio_ClinicalBERT' (or change to try others)\n",
    "model_choice = model_keys[model_index]\n",
    "model_info = available_models[model_choice]\n",
    "\n",
    "print(f\"\n",
    "Selected model: {model_info['model_name']}\n",
    "  Description: {model_info['description']}\n",
    "  Entity Types: {model_info['entity_types']}\")\n",
    "\n",
    "# --- 4. Build the Pipeline ---\n",
    "\n",
    "ner_pipe = pipeline('ner', model=model_info['model_name'], tokenizer=model_info['model_name'], aggregation_strategy=\"simple\")\n",
    "\n",
    "# Parameters to experiment with\n",
    "aggregation_strategy = 'simple'  # Try 'none', 'first', 'average', 'simple' (see documentation)\n",
    "max_length = 256  # Adjust as needed for context window (esp. for long clinical notes)\n",
    "\n",
    "# --- 5. Run Entity Extraction Pipeline ---\n",
    "def extract_entities(texts: List[str],\n",
    "                    nlp_pipe,\n",
    "                    aggregation_strategy: str = 'simple',\n",
    "                    max_length: int = 256) -> List[List[Dict]]:\n",
    "    \"\"\"Apply NER pipeline to a list of texts, return extracted entities for each.\"\"\"\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        try:\n",
    "            ents = nlp_pipe(\n",
    "                text,\n",
    "                aggregation_strategy=aggregation_strategy,\n",
    "                truncation=True,\n",
    "                max_length=max_length\n",
    "            )\n",
    "        except Exception as e:\n",
    "            ents = []\n",
    "        results.append(ents)\n",
    "    return results\n",
    "\n",
    "clinical_notes_df['entities'] = extract_entities(\n",
    "    clinical_notes_df['note_text'].tolist(),\n",
    "    ner_pipe,\n",
    "    aggregation_strategy=aggregation_strategy,\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "def display_entities(df: pd.DataFrame, limit: int = 5):\n",
    "    \"\"\"Nicely display clinical notes and their recognized entities.\"\"\"\n",
    "    for idx, row in df.head(limit).iterrows():\n",
    "        entities_md = []\n",
    "        entities = row['entities']\n",
    "        if entities:\n",
    "            for ent in entities:\n",
    "                ent_text = ent.get('word', ent.get('entity_group', ''))\n",
    "                ent_label = ent.get('entity_group', ent.get('entity', ''))\n",
    "                score = ent.get('score', 0)\n",
    "                entities_md.append(f\"- **{ent_label}**: '{ent_text}' (score: {score:.2f})\")\n",
    "        else:\n",
    "            entities_md.append('*No entities recognized.*')\n",
    "        display(Markdown(f\"---\n",
    "**Clinical Note {row['note_id']}:**\n",
    "{text_wrap(row['note_text'], width=100)}\n",
    "\n",
    "**Extracted Entities:**\n",
    "\" + '\n",
    "'.join(entities_md)))\n",
    "\n",
    "def text_wrap(text: str, width: int = 80) -> str:\n",
    "    \"\"\"Utility for word-wrapping text for readability in display.\"\"\"\n",
    "    import textwrap\n",
    "    return '\n",
    "'.join(textwrap.wrap(text, width=width))\n",
    "\n",
    "display(Markdown('---\n",
    "#### Entity Recognition Results (First 5 Notes):'))\n",
    "display_entities(clinical_notes_df, limit=5)\n",
    "\n",
    "# --- 6. Experimentation: Try Swapping Models or Parameters ---\n",
    "# You can rerun the pipeline with different 'available_models', 'aggregation_strategy', or 'max_length'.\n",
    "# For demonstration, let's run with a general-domain model for comparison:\n",
    "\n",
    "other_model_key = 'distilbert-base-uncased-finetuned-ner'\n",
    "other_model_info = available_models[other_model_key]\n",
    "print(f\"\n",
    "Comparison: Running with control model: {other_model_info['model_name']}\")\n",
    "other_ner_pipe = pipeline('ner', model=other_model_info['model_name'], tokenizer=other_model_info['model_name'], aggregation_strategy=aggregation_strategy)\n",
    "clinical_notes_df['entities_control'] = extract_entities(\n",
    "    clinical_notes_df['note_text'].tolist(),\n",
    "    other_ner_pipe,\n",
    "    aggregation_strategy=aggregation_strategy,\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "def compare_entities(df: pd.DataFrame, limit: int = 5):\n",
    "    for idx, row in df.head(limit).iterrows():\n",
    "        ents_domain = row['entities']\n",
    "        ents_control = row['entities_control']\n",
    "        ents_domain_md = []\n",
    "        ents_control_md = []\n",
    "        if ents_domain:\n",
    "            for ent in ents_domain:\n",
    "                ent_text = ent.get('word', ent.get('entity_group', ''))\n",
    "                ent_label = ent.get('entity_group', ent.get('entity', ''))\n",
    "                ents_domain_md.append(f\"- **{ent_label}**: '{ent_text}'\")\n",
    "        else:\n",
    "            ents_domain_md.append('*None*')\n",
    "        if ents_control:\n",
    "            for ent in ents_control:\n",
    "                ent_text = ent.get('word', ent.get('entity_group', ''))\n",
    "                ent_label = ent.get('entity_group', ent.get('entity', ''))\n",
    "                ents_control_md.append(f\"- **{ent_label}**: '{ent_text}'\")\n",
    "        else:\n",
    "            ents_control_md.append('*None*')\n",
    "        md = f\"---\n",
    "**Clinical Note {row['note_id']}:**\n",
    "{text_wrap(row['note_text'], width=80)}\n",
    "\n",
    "> **Domain-specific model ({model_info['model_name']}) entities:**\n",
    "\" + '\n",
    "'.join(ents_domain_md)\n",
    "        md += f\"\n",
    "\n",
    "> **General model ({other_model_info['model_name']}) entities:**\n",
    "\" + '\n",
    "'.join(ents_control_md)\n",
    "        display(Markdown(md))\n",
    "\n",
    "display(Markdown('### Model Comparison: Clinical vs General NER Results'))\n",
    "compare_entities(clinical_notes_df, limit=5)\n",
    "\n",
    "# --- 7. Documentation: Experimentation & Model Performance Notes ---\n",
    "\n",
    "experiment_notes = '''\n",
    "## Experiment Notes: Rapid NLP Pipeline Prototyping\n",
    "\n",
    "- **Model Selection Impact:**\n",
    "    - Domain-specific models (e.g., Bio_ClinicalBERT, BioBERT-NER) tend to extract medical concepts (diagnoses, symptoms, medications) more accurately and with appropriate labeling, compared to general NER baselines.\n",
    "    - General models (like distilbert-base-uncased-finetuned-ner) primarily label entities as PERSON/ORG/LOC/MISC; clinical details may be missed or mis-labeled.\n",
    "\n",
    "- **Parameter Choices:**\n",
    "    - `aggregation_strategy` controls entity grouping and can affect granularity. For short input, 'simple' works well; 'none' returns more verbose outputs.\n",
    "    - `max_length` impacts handling of long clinical notes. For very long notes, split into sentences or adjust max_length accordingly.\n",
    "    - Some biomedical NER models do not support aggregation_strategy or may have different output formats (check documentation as models evolve).\n",
    "\n",
    "- **Observations:**\n",
    "    - The reusable, parameterized pipeline structure allows rapid swapping of models and tuning for best entity extraction quality.\n",
    "    - Differences in recognized entities and label types are evident when changing from a domain-specific to a general-purpose model.\n",
    "    - For production, prefer clinical-domain models when available, and always evaluate model performance using a labeled test set.\n",
    "'''\n",
    "display(Markdown(experiment_notes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5733c10",
   "metadata": {},
   "source": [
    "Analyze and Visualize Synthetic Data Generated via Reusable Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Data Generation, Visualization, and Privacy/Fidelity Analysis for Healthcare\n",
    "\n",
    "# --- 1. Setup: Imports & Environment ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "import random\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- 2. Select Data Type to Generate (Tabular or Textual) ---\n",
    "\n",
    "def select_data_type():\n",
    "    print(\"Select data type to generate:\")\n",
    "    print(\"1. Tabular synthetic patient data (structured)\")\n",
    "    print(\"2. Synthetic clinical notes (textual)\")\n",
    "    choice = ''\n",
    "    while choice not in ['1', '2']:\n",
    "        try:\n",
    "            choice = input(\"Enter '1' for tabular, '2' for text: \").strip()\n",
    "        except Exception:\n",
    "            choice = '1'  # For non-interactive execution, default to '1'\n",
    "    return choice\n",
    "\n",
    "# In notebooks, we can gracefully default to tabular data for reproducibility\n",
    "try:\n",
    "    data_type_choice = select_data_type()\n",
    "except Exception:\n",
    "    data_type_choice = '1'\n",
    "\n",
    "# --- 3A. Generate Synthetic Tabular Healthcare Data ---\n",
    "def generate_synthetic_tabular(n_samples: int = 300, random_seed: int = 42) -> pd.DataFrame:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    data = {\n",
    "        'patient_id': range(1, n_samples + 1),\n",
    "        'age': np.random.normal(loc=57, scale=17, size=n_samples).astype(int),\n",
    "        'sex': np.random.choice(['Male', 'Female'], size=n_samples),\n",
    "        'admission_type': np.random.choice(['Emergency', 'Elective', 'Urgent'], size=n_samples, p=[0.5, 0.3, 0.2]),\n",
    "        'systolic_bp': np.random.normal(loc=128, scale=16, size=n_samples),\n",
    "        'diastolic_bp': np.random.normal(loc=77, scale=9, size=n_samples),\n",
    "        'glucose': np.random.normal(loc=105, scale=21, size=n_samples),\n",
    "        'length_of_stay': np.abs(np.random.normal(loc=5.5, scale=3.1, size=n_samples)),\n",
    "        'discharge_status': np.random.choice(['Home', 'Transferred', 'Deceased'], size=n_samples, p=[0.82, 0.14, 0.04])\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    # Clip and round for realism\n",
    "    df['age'] = df['age'].clip(0, 100)\n",
    "    df['systolic_bp'] = np.round(df['systolic_bp'], 1)\n",
    "    df['diastolic_bp'] = np.round(df['diastolic_bp'], 1)\n",
    "    df['glucose'] = np.round(df['glucose'], 1)\n",
    "    df['length_of_stay'] = np.round(df['length_of_stay'], 1)\n",
    "    return df\n",
    "\n",
    "# --- 3B. Generate Synthetic Clinical Notes (Textual) ---\n",
    "def generate_synthetic_notes(n_samples: int = 10, random_seed: int = 42) -> pd.DataFrame:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    # Define vocabulary and templates\n",
    "    diseases = ['hypertension', 'diabetes', 'pneumonia', 'migraine', 'heart failure', 'asthma', 'COPD', 'stroke']\n",
    "    meds = ['metformin', 'lisinopril', 'azithromycin', 'furosemide', 'spironolactone', 'acetaminophen']\n",
    "    findings = ['chest pain', 'shortness of breath', 'cough', 'headache', 'vision changes', 'back pain', 'fatigue', 'fever']\n",
    "    diagnostics = ['EKG shows normal sinus rhythm', 'MRI lumbar reveals spondylosis', 'oxygen saturation at 92%', 'no evidence of infection']\n",
    "    templates = [\n",
    "        \"Patient presents with [finding]. Past history includes [disease1] and [disease2]. Medications: [med1], [med2]. [diagnostic].\",\n",
    "        \"Admitted for [finding]. Treated with [med1]. {diagnostic}. Discharged in stable condition.\",\n",
    "        \"Complaints of [finding]. Prescribed [med1] for suspected [disease1]. No prior [disease2] noted.\",\n",
    "        \"Experienced [finding]. Family history includes [disease1]. Managed with [med1].\",\n",
    "        \"Reports [finding] and [finding2]. Imaging: [diagnostic]. Monitored for possible [disease1].\"\n",
    "    ]\n",
    "    notes = []\n",
    "    for i in range(n_samples):\n",
    "        t = random.choice(templates)\n",
    "        note = t.replace('[finding]', random.choice(findings))                .replace('[disease1]', random.choice(diseases))                .replace('[disease2]', random.choice(diseases))                .replace('[med1]', random.choice(meds))                .replace('[med2]', random.choice(meds))                .replace('[diagnostic]', random.choice(diagnostics))                .replace('[finding2]', random.choice(findings))\n",
    "        # The '{diagnostic}' placeholder for 2nd template\n",
    "        note = note.replace('{diagnostic}', random.choice(diagnostics))\n",
    "        notes.append(note)\n",
    "    df = pd.DataFrame({'note_id': range(1, n_samples+1), 'note_text': notes})\n",
    "    return df\n",
    "\n",
    "# --- 4. Load or Generate (Optionally Also Load 'real' Data for Comparison) ---\n",
    "# For this demonstration, we'll treat the previous EDA dataset as 'real' data for tabular comparison.\n",
    "\n",
    "if data_type_choice == '1':\n",
    "    # Tabular synthetic data\n",
    "    synthetic_df = generate_synthetic_tabular(n_samples=300)\n",
    "    try:\n",
    "        # Try to use the dataset from previous activity as 'real' data for comparison\n",
    "        # Assume variable health_df is present; otherwise, generate similar real data\n",
    "        real_df = health_df.copy()\n",
    "    except Exception:\n",
    "        real_df = generate_synthetic_tabular(n_samples=300, random_seed=777)\n",
    "    display(Markdown('### Tabular Synthetic Healthcare Data (*first 6 rows*)'))\n",
    "    display(synthetic_df.head(6))\n",
    "else:\n",
    "    # Synthetic textual data\n",
    "    synthetic_df = generate_synthetic_notes(n_samples=8)\n",
    "    display(Markdown('### Synthetic Clinical Notes (*first 5*)'))\n",
    "    display(synthetic_df.head(5))\n",
    "\n",
    "# --- 5. Visualize and Compare Distributions (Tabular Data) ---\n",
    "\n",
    "def plot_distribution_compare(syn: pd.DataFrame, real: pd.DataFrame, column: str, bins: int = 20, title: str = None):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.histplot(real[column], color='skyblue', label='Real', kde=True, stat='density', bins=bins, alpha=0.55)\n",
    "    sns.histplot(syn[column], color='salmon', label='Synthetic', kde=True, stat='density', bins=bins, alpha=0.55)\n",
    "    plt.legend()\n",
    "    plt.xlabel(column)\n",
    "    plt.title(title or f\"Distribution of {column}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_categorical_compare(syn: pd.DataFrame, real: pd.DataFrame, column: str, title: str = None):\n",
    "    plt.figure(figsize=(6,3))\n",
    "    syn_counts = syn[column].value_counts(normalize=True).sort_index()\n",
    "    real_counts = real[column].value_counts(normalize=True).sort_index()\n",
    "    width = 0.35\n",
    "    idx = np.arange(len(syn_counts))\n",
    "    plt.bar(idx-width/2, real_counts.values, width=width, color='skyblue', label='Real')\n",
    "    plt.bar(idx+width/2, syn_counts.values, width=width, color='salmon', label='Synthetic')\n",
    "    plt.xticks(idx, syn_counts.index)\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.title(title or f\"{column}: Real vs Synthetic\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if data_type_choice == '1':\n",
    "    # Continuous columns\n",
    "    for col in ['age', 'systolic_bp', 'diastolic_bp', 'glucose', 'length_of_stay']:\n",
    "        plot_distribution_compare(synthetic_df, real_df, col, title=f\"{col.title()} Distribution: Real vs Synthetic\")\n",
    "    # Categorical columns\n",
    "    for cat in ['sex', 'admission_type', 'discharge_status']:\n",
    "        plot_categorical_compare(synthetic_df, real_df, cat, title=f\"{cat.replace('_',' ').title()}: Real vs Synthetic\")\n",
    "\n",
    "# --- 6. NLP and Statistics for Synthetic Textual Data ---\n",
    "if data_type_choice == '2':\n",
    "    # Simple statistics: length, vocabulary, n-grams (no ML models here, just basic fidelity metrics)\n",
    "    synthetic_df['num_words'] = synthetic_df['note_text'].apply(lambda s: len(s.split()))\n",
    "    synthetic_df['num_chars'] = synthetic_df['note_text'].apply(len)\n",
    "    display(Markdown('#### Statistics of Synthetic Clinical Notes'))\n",
    "    display(synthetic_df[['note_id', 'num_words', 'num_chars']].describe())\n",
    "    # Show text diversity (basic n-gram coverage)\n",
    "    from collections import Counter\n",
    "    all_text = ' '.join(synthetic_df['note_text']).lower().split()\n",
    "    vocab = set(all_text)\n",
    "    word_counts = Counter(all_text)\n",
    "    top_words = word_counts.most_common(10)\n",
    "    display(Markdown(f\"**Vocabulary size:** {len(vocab)}\"))\n",
    "    display(Markdown(f\"**Top 10 most common words:** {', '.join(f'{w} ({c})' for w,c in top_words)}\"))\n",
    "    # Word length histogram\n",
    "    plt.figure(figsize=(5,2.5))\n",
    "    sns.histplot(synthetic_df['num_words'], bins=8, color='orchid', edgecolor='black')\n",
    "    plt.title('Synthetic Note Length (words)')\n",
    "    plt.xlabel('Num words per note')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- 7. Privacy & Utility Discussion (Markdown cell) ---\n",
    "report_md = '''\n",
    "## Utility and Privacy of Generated Synthetic Data\n",
    "\n",
    "- **Utility:**\n",
    "    - Synthetic tabular data imitates real patient distributions and enables rapid prototyping for research, visualization, or algorithmic testing without patient privacy risk.\n",
    "    - The synthetic clinical notes reflect plausible combinations of medical concepts, supporting NLP model testing and iterative prompt engineering.\n",
    "    - Visual comparison demonstrates good alignment in/univariate statistics; for deeper fidelity, advanced methods (e.g. GANs, copulas, or language models) may be considered.\n",
    "\n",
    "- **Privacy:**\n",
    "    - All data is programmatically generated, guaranteeing that no individually-identifying patient information is present.\n",
    "    - Distributional or summary-level attacks are not meaningful (there is no one-to-one mapping with actual patients).\n",
    "    - For deployment in sensitive settings, privacy-preserving approaches (differential privacy, noise injection, output audits) can further strengthen guarantees.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "This notebook supports safe, rapid synthetic healthcare data prototyping, visualization, and model pipeline validation, with explicit separation from true patient data. Researchers should always validate downstream analysis pipelines for generalizability beyond synthetic benchmarks.\n",
    "'''\n",
    "display(Markdown(report_md))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91252c2",
   "metadata": {},
   "source": [
    "Perform Exploratory Data Analysis (EDA) Using Matplotlib and Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f58288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis on Healthcare Datasets\n",
    "\n",
    "# In this notebook, we will conduct exploratory data analysis (EDA) on structured healthcare data.\n",
    "# We will use matplotlib and seaborn to visualize and interpret key aspects, focusing on trends and potential anomalies.\n",
    "\n",
    "# --- 1. Imports & Setup ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Inline plotting for Jupyter Notebooks\n",
    "try:\n",
    "    get_ipython()\n",
    "    # This will work only in Jupyter; safe to ignore elsewhere\n",
    "    %matplotlib inline  # noqa: E402,F821\n",
    "except NameError:\n",
    "    pass  # Not running inside IPython/Jupyter\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- 2. Data Loading ---\n",
    "# For demonstration, we will create a synthetic healthcare dataset (since file paths are not provided).\n",
    "# The dataset structure follows common healthcare metrics: patient_id, age, gender, admission_type,\n",
    "# lab result values (e.g., blood pressure, glucose), and length_of_stay.\n",
    "data = {\n",
    "    'patient_id': range(1, 301),\n",
    "    'age': np.random.normal(loc=55, scale=18, size=300).astype(int),\n",
    "    'gender': np.random.choice(['Male', 'Female'], size=300),\n",
    "    'admission_type': np.random.choice(\n",
    "        ['Emergency', 'Elective', 'Urgent'],\n",
    "        size=300, p=[0.5, 0.3, 0.2]\n",
    "    ),\n",
    "    'systolic_bp': np.random.normal(loc=130, scale=15, size=300),\n",
    "    'diastolic_bp': np.random.normal(loc=80, scale=8, size=300),\n",
    "    'glucose': np.random.normal(loc=100, scale=25, size=300),\n",
    "    'length_of_stay': np.abs(np.random.normal(loc=6, scale=3, size=300)),\n",
    "    'discharge_status': np.random.choice(\n",
    "        ['Home', 'Transferred', 'Deceased'],\n",
    "        size=300, p=[0.8, 0.16, 0.04]\n",
    "    )\n",
    "}\n",
    "health_df = pd.DataFrame(data)\n",
    "\n",
    "# Clip age to plausible bounds and round where appropriate\n",
    "health_df['age'] = health_df['age'].clip(lower=0, upper=100)\n",
    "health_df['glucose'] = np.round(health_df['glucose'], 1)\n",
    "health_df['systolic_bp'] = np.round(health_df['systolic_bp'], 1)\n",
    "health_df['diastolic_bp'] = np.round(health_df['diastolic_bp'], 1)\n",
    "health_df['length_of_stay'] = np.round(health_df['length_of_stay'], 1)\n",
    "\n",
    "# --- 3. Preview & Summary ---\n",
    "# Import display explicitly from IPython.display to avoid undefined symbol error\n",
    "from IPython.display import display\n",
    "\n",
    "display(health_df.head())\n",
    "print('Shape:', health_df.shape)\n",
    "display(health_df.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49ce1ac",
   "metadata": {},
   "source": [
    "Experiment with Reusable NLP Pipeline Notebook for Clinical Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e570c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reusable NLP Pipeline for Clinical Text Understanding ---\n",
    "#\n",
    "# This notebook demonstrates rapid experimentation with transformer-based NLP models for\n",
    "# clinical named entity recognition (NER) and information extraction. You can select different models, adjust pipeline parameters,\n",
    "# and observe effects on medical entity extraction (diagnoses, symptoms, medications, etc).\n",
    "#\n",
    "# --- 1. Setup & Imports ---\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Hugging Face transformers for modern NER\n",
    "from transformers import pipeline\n",
    "\n",
    "# --- 2. Load Sample, De-identified Clinical Notes ---\n",
    "# For demonstration, we'll use synthetic, de-identified clinical text snippets.\n",
    "# In practice, replace 'clinical_notes_df' with your real data (ensuring all PHI is properly handled).\n",
    "\n",
    "sample_notes = [\n",
    "    \"Patient presents with 2-day history of chest pain. Past history of hypertension, diabetes. Medications include metformin and lisinopril. EKG shows normal sinus rhythm.\",\n",
    "    \"Admitted for acute shortness of breath. Started on intravenous furosemide. Oxygen saturation 91%. Diagnosed with heart failure exacerbation. Discharged on spironolactone.\",\n",
    "    \"Complaints of worsening cough. Prescribed azithromycin for suspected pneumonia. No prior COPD or asthma noted.\",\n",
    "    \"Severe headache, vision changes. Brain MRI scheduled. No evidence of infection. Monitored for possible migraine or vascular event.\",\n",
    "    \"Reports chronic back pain, managed on acetaminophen. MRI lumbar shows mild spondylosis.\"    \n",
    "]\n",
    "clinical_notes_df = pd.DataFrame({'note_id': range(1, len(sample_notes)+1), 'note_text': sample_notes})\n",
    "\n",
    "display(Markdown('### Sample De-identified Clinical Notes'))\n",
    "display(clinical_notes_df)\n",
    "\n",
    "# --- 3. NLP Model Selection ---\n",
    "# Define several transformer-based NER pipelines (from HuggingFace Hub), suitable for clinical/biomedical entity extraction.\n",
    "# You may experiment with different models for comparison.\n",
    "\n",
    "available_models = {\n",
    "    'distilbert-base-uncased-finetuned-ner': {\n",
    "        'description': 'General-purpose NER (baseline)',\n",
    "        'model_name': 'distilbert-base-uncased-finetuned-ner',\n",
    "        'entity_types': 'person, org, loc, misc (general NER; use as control)'},\n",
    "    'dslim/bert-base-NER': {\n",
    "        'description': 'BERT for general NER (benchmark)',\n",
    "        'model_name': 'dslim/bert-base-NER',\n",
    "        'entity_types': 'person, org, loc, misc (general NER; control)'},\n",
    "    'emilyalsentzer/Bio_ClinicalBERT': {\n",
    "        'description': 'Bio_ClinicalBERT: Clinical/biomedical text',\n",
    "        'model_name': 'emilyalsentzer/Bio_ClinicalBERT',\n",
    "        'entity_types': 'biomedical: diseases, symptoms, medications (may require fine-tuning, demo only)'},\n",
    "    'kamalkraj/BioBERT-NER': {\n",
    "        'description': 'BioBERT NER (biomedical baseline)',\n",
    "        'model_name': 'kamalkraj/BioBERT-NER',\n",
    "        'entity_types': 'biomedical: diseases, chemicals, genes, symptoms'},\n",
    "    # Add more domain-specific models as desired\n",
    "}\n",
    "\n",
    "print('Available models:')\n",
    "for idx, (k, v) in enumerate(available_models.items()):\n",
    "    print(f\"[{idx}] {k} - {v['description']} ({v['entity_types']})\")\n",
    "    \n",
    "# You may modify here to experiment\n",
    "model_keys = list(available_models.keys())\n",
    "model_index = 2  # Default: use 'emilyalsentzer/Bio_ClinicalBERT' (or change to try others)\n",
    "model_choice = model_keys[model_index]\n",
    "model_info = available_models[model_choice]\n",
    "\n",
    "print(f\"\n",
    "Selected model: {model_info['model_name']}\n",
    "  Description: {model_info['description']}\n",
    "  Entity Types: {model_info['entity_types']}\")\n",
    "\n",
    "# --- 4. Build the Pipeline ---\n",
    "\n",
    "ner_pipe = pipeline('ner', model=model_info['model_name'], tokenizer=model_info['model_name'], aggregation_strategy=\"simple\")\n",
    "\n",
    "# Parameters to experiment with\n",
    "aggregation_strategy = 'simple'  # Try 'none', 'first', 'average', 'simple' (see documentation)\n",
    "max_length = 256  # Adjust as needed for context window (esp. for long clinical notes)\n",
    "\n",
    "# --- 5. Run Entity Extraction Pipeline ---\n",
    "def extract_entities(texts: List[str],\n",
    "                    nlp_pipe,\n",
    "                    aggregation_strategy: str = 'simple',\n",
    "                    max_length: int = 256) -> List[List[Dict]]:\n",
    "    \"\"\"Apply NER pipeline to a list of texts, return extracted entities for each.\"\"\"\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        try:\n",
    "            ents = nlp_pipe(\n",
    "                text,\n",
    "                aggregation_strategy=aggregation_strategy,\n",
    "                truncation=True,\n",
    "                max_length=max_length\n",
    "            )\n",
    "        except Exception as e:\n",
    "            ents = []\n",
    "        results.append(ents)\n",
    "    return results\n",
    "\n",
    "clinical_notes_df['entities'] = extract_entities(\n",
    "    clinical_notes_df['note_text'].tolist(),\n",
    "    ner_pipe,\n",
    "    aggregation_strategy=aggregation_strategy,\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "def display_entities(df: pd.DataFrame, limit: int = 5):\n",
    "    \"\"\"Nicely display clinical notes and their recognized entities.\"\"\"\n",
    "    for idx, row in df.head(limit).iterrows():\n",
    "        entities_md = []\n",
    "        entities = row['entities']\n",
    "        if entities:\n",
    "            for ent in entities:\n",
    "                ent_text = ent.get('word', ent.get('entity_group', ''))\n",
    "                ent_label = ent.get('entity_group', ent.get('entity', ''))\n",
    "                score = ent.get('score', 0)\n",
    "                entities_md.append(f\"- **{ent_label}**: '{ent_text}' (score: {score:.2f})\")\n",
    "        else:\n",
    "            entities_md.append('*No entities recognized.*')\n",
    "        display(Markdown(f\"---\n",
    "**Clinical Note {row['note_id']}:**\n",
    "{text_wrap(row['note_text'], width=100)}\n",
    "\n",
    "**Extracted Entities:**\n",
    "\" + '\n",
    "'.join(entities_md)))\n",
    "\n",
    "def text_wrap(text: str, width: int = 80) -> str:\n",
    "    \"\"\"Utility for word-wrapping text for readability in display.\"\"\"\n",
    "    import textwrap\n",
    "    return '\n",
    "'.join(textwrap.wrap(text, width=width))\n",
    "\n",
    "display(Markdown('---\n",
    "#### Entity Recognition Results (First 5 Notes):'))\n",
    "display_entities(clinical_notes_df, limit=5)\n",
    "\n",
    "# --- 6. Experimentation: Try Swapping Models or Parameters ---\n",
    "# You can rerun the pipeline with different 'available_models', 'aggregation_strategy', or 'max_length'.\n",
    "# For demonstration, let's run with a general-domain model for comparison:\n",
    "\n",
    "other_model_key = 'distilbert-base-uncased-finetuned-ner'\n",
    "other_model_info = available_models[other_model_key]\n",
    "print(f\"\n",
    "Comparison: Running with control model: {other_model_info['model_name']}\")\n",
    "other_ner_pipe = pipeline('ner', model=other_model_info['model_name'], tokenizer=other_model_info['model_name'], aggregation_strategy=aggregation_strategy)\n",
    "clinical_notes_df['entities_control'] = extract_entities(\n",
    "    clinical_notes_df['note_text'].tolist(),\n",
    "    other_ner_pipe,\n",
    "    aggregation_strategy=aggregation_strategy,\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "def compare_entities(df: pd.DataFrame, limit: int = 5):\n",
    "    for idx, row in df.head(limit).iterrows():\n",
    "        ents_domain = row['entities']\n",
    "        ents_control = row['entities_control']\n",
    "        ents_domain_md = []\n",
    "        ents_control_md = []\n",
    "        if ents_domain:\n",
    "            for ent in ents_domain:\n",
    "                ent_text = ent.get('word', ent.get('entity_group', ''))\n",
    "                ent_label = ent.get('entity_group', ent.get('entity', ''))\n",
    "                ents_domain_md.append(f\"- **{ent_label}**: '{ent_text}'\")\n",
    "        else:\n",
    "            ents_domain_md.append('*None*')\n",
    "        if ents_control:\n",
    "            for ent in ents_control:\n",
    "                ent_text = ent.get('word', ent.get('entity_group', ''))\n",
    "                ent_label = ent.get('entity_group', ent.get('entity', ''))\n",
    "                ents_control_md.append(f\"- **{ent_label}**: '{ent_text}'\")\n",
    "        else:\n",
    "            ents_control_md.append('*None*')\n",
    "        md = f\"---\n",
    "**Clinical Note {row['note_id']}:**\n",
    "{text_wrap(row['note_text'], width=80)}\n",
    "\n",
    "> **Domain-specific model ({model_info['model_name']}) entities:**\n",
    "\" + '\n",
    "'.join(ents_domain_md)\n",
    "        md += f\"\n",
    "\n",
    "> **General model ({other_model_info['model_name']}) entities:**\n",
    "\" + '\n",
    "'.join(ents_control_md)\n",
    "        display(Markdown(md))\n",
    "\n",
    "display(Markdown('### Model Comparison: Clinical vs General NER Results'))\n",
    "compare_entities(clinical_notes_df, limit=5)\n",
    "\n",
    "# --- 7. Documentation: Experimentation & Model Performance Notes ---\n",
    "\n",
    "experiment_notes = '''\n",
    "## Experiment Notes: Rapid NLP Pipeline Prototyping\n",
    "\n",
    "- **Model Selection Impact:**\n",
    "    - Domain-specific models (e.g., Bio_ClinicalBERT, BioBERT-NER) tend to extract medical concepts (diagnoses, symptoms, medications) more accurately and with appropriate labeling, compared to general NER baselines.\n",
    "    - General models (like distilbert-base-uncased-finetuned-ner) primarily label entities as PERSON/ORG/LOC/MISC; clinical details may be missed or mis-labeled.\n",
    "\n",
    "- **Parameter Choices:**\n",
    "    - `aggregation_strategy` controls entity grouping and can affect granularity. For short input, 'simple' works well; 'none' returns more verbose outputs.\n",
    "    - `max_length` impacts handling of long clinical notes. For very long notes, split into sentences or adjust max_length accordingly.\n",
    "    - Some biomedical NER models do not support aggregation_strategy or may have different output formats (check documentation as models evolve).\n",
    "\n",
    "- **Observations:**\n",
    "    - The reusable, parameterized pipeline structure allows rapid swapping of models and tuning for best entity extraction quality.\n",
    "    - Differences in recognized entities and label types are evident when changing from a domain-specific to a general-purpose model.\n",
    "    - For production, prefer clinical-domain models when available, and always evaluate model performance using a labeled test set.\n",
    "'''\n",
    "display(Markdown(experiment_notes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d782025",
   "metadata": {},
   "source": [
    "Analyze and Visualize Synthetic Data Generated via Reusable Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Data Generation, Visualization, and Privacy/Fidelity Analysis for Healthcare\n",
    "\n",
    "# --- 1. Setup: Imports & Environment ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "import random\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- 2. Select Data Type to Generate (Tabular or Textual) ---\n",
    "\n",
    "def select_data_type():\n",
    "    print(\"Select data type to generate:\")\n",
    "    print(\"1. Tabular synthetic patient data (structured)\")\n",
    "    print(\"2. Synthetic clinical notes (textual)\")\n",
    "    choice = ''\n",
    "    while choice not in ['1', '2']:\n",
    "        try:\n",
    "            choice = input(\"Enter '1' for tabular, '2' for text: \").strip()\n",
    "        except Exception:\n",
    "            choice = '1'  # For non-interactive execution, default to '1'\n",
    "    return choice\n",
    "\n",
    "# In notebooks, we can gracefully default to tabular data for reproducibility\n",
    "try:\n",
    "    data_type_choice = select_data_type()\n",
    "except Exception:\n",
    "    data_type_choice = '1'\n",
    "\n",
    "# --- 3A. Generate Synthetic Tabular Healthcare Data ---\n",
    "def generate_synthetic_tabular(n_samples: int = 300, random_seed: int = 42) -> pd.DataFrame:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    data = {\n",
    "        'patient_id': range(1, n_samples + 1),\n",
    "        'age': np.random.normal(loc=57, scale=17, size=n_samples).astype(int),\n",
    "        'sex': np.random.choice(['Male', 'Female'], size=n_samples),\n",
    "        'admission_type': np.random.choice(['Emergency', 'Elective', 'Urgent'], size=n_samples, p=[0.5, 0.3, 0.2]),\n",
    "        'systolic_bp': np.random.normal(loc=128, scale=16, size=n_samples),\n",
    "        'diastolic_bp': np.random.normal(loc=77, scale=9, size=n_samples),\n",
    "        'glucose': np.random.normal(loc=105, scale=21, size=n_samples),\n",
    "        'length_of_stay': np.abs(np.random.normal(loc=5.5, scale=3.1, size=n_samples)),\n",
    "        'discharge_status': np.random.choice(['Home', 'Transferred', 'Deceased'], size=n_samples, p=[0.82, 0.14, 0.04])\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    # Clip and round for realism\n",
    "    df['age'] = df['age'].clip(0, 100)\n",
    "    df['systolic_bp'] = np.round(df['systolic_bp'], 1)\n",
    "    df['diastolic_bp'] = np.round(df['diastolic_bp'], 1)\n",
    "    df['glucose'] = np.round(df['glucose'], 1)\n",
    "    df['length_of_stay'] = np.round(df['length_of_stay'], 1)\n",
    "    return df\n",
    "\n",
    "# --- 3B. Generate Synthetic Clinical Notes (Textual) ---\n",
    "def generate_synthetic_notes(n_samples: int = 10, random_seed: int = 42) -> pd.DataFrame:\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    # Define vocabulary and templates\n",
    "    diseases = ['hypertension', 'diabetes', 'pneumonia', 'migraine', 'heart failure', 'asthma', 'COPD', 'stroke']\n",
    "    meds = ['metformin', 'lisinopril', 'azithromycin', 'furosemide', 'spironolactone', 'acetaminophen']\n",
    "    findings = ['chest pain', 'shortness of breath', 'cough', 'headache', 'vision changes', 'back pain', 'fatigue', 'fever']\n",
    "    diagnostics = ['EKG shows normal sinus rhythm', 'MRI lumbar reveals spondylosis', 'oxygen saturation at 92%', 'no evidence of infection']\n",
    "    templates = [\n",
    "        \"Patient presents with [finding]. Past history includes [disease1] and [disease2]. Medications: [med1], [med2]. [diagnostic].\",\n",
    "        \"Admitted for [finding]. Treated with [med1]. {diagnostic}. Discharged in stable condition.\",\n",
    "        \"Complaints of [finding]. Prescribed [med1] for suspected [disease1]. No prior [disease2] noted.\",\n",
    "        \"Experienced [finding]. Family history includes [disease1]. Managed with [med1].\",\n",
    "        \"Reports [finding] and [finding2]. Imaging: [diagnostic]. Monitored for possible [disease1].\"\n",
    "    ]\n",
    "    notes = []\n",
    "    for i in range(n_samples):\n",
    "        t = random.choice(templates)\n",
    "        note = t.replace('[finding]', random.choice(findings))                .replace('[disease1]', random.choice(diseases))                .replace('[disease2]', random.choice(diseases))                .replace('[med1]', random.choice(meds))                .replace('[med2]', random.choice(meds))                .replace('[diagnostic]', random.choice(diagnostics))                .replace('[finding2]', random.choice(findings))\n",
    "        # The '{diagnostic}' placeholder for 2nd template\n",
    "        note = note.replace('{diagnostic}', random.choice(diagnostics))\n",
    "        notes.append(note)\n",
    "    df = pd.DataFrame({'note_id': range(1, n_samples+1), 'note_text': notes})\n",
    "    return df\n",
    "\n",
    "# --- 4. Load or Generate (Optionally Also Load 'real' Data for Comparison) ---\n",
    "# For this demonstration, we'll treat the previous EDA dataset as 'real' data for tabular comparison.\n",
    "\n",
    "if data_type_choice == '1':\n",
    "    # Tabular synthetic data\n",
    "    synthetic_df = generate_synthetic_tabular(n_samples=300)\n",
    "    try:\n",
    "        # Try to use the dataset from previous activity as 'real' data for comparison\n",
    "        # Assume variable health_df is present; otherwise, generate similar real data\n",
    "        real_df = health_df.copy()\n",
    "    except Exception:\n",
    "        real_df = generate_synthetic_tabular(n_samples=300, random_seed=777)\n",
    "    display(Markdown('### Tabular Synthetic Healthcare Data (*first 6 rows*)'))\n",
    "    display(synthetic_df.head(6))\n",
    "else:\n",
    "    # Synthetic textual data\n",
    "    synthetic_df = generate_synthetic_notes(n_samples=8)\n",
    "    display(Markdown('### Synthetic Clinical Notes (*first 5*)'))\n",
    "    display(synthetic_df.head(5))\n",
    "\n",
    "# --- 5. Visualize and Compare Distributions (Tabular Data) ---\n",
    "\n",
    "def plot_distribution_compare(syn: pd.DataFrame, real: pd.DataFrame, column: str, bins: int = 20, title: str = None):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.histplot(real[column], color='skyblue', label='Real', kde=True, stat='density', bins=bins, alpha=0.55)\n",
    "    sns.histplot(syn[column], color='salmon', label='Synthetic', kde=True, stat='density', bins=bins, alpha=0.55)\n",
    "    plt.legend()\n",
    "    plt.xlabel(column)\n",
    "    plt.title(title or f\"Distribution of {column}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_categorical_compare(syn: pd.DataFrame, real: pd.DataFrame, column: str, title: str = None):\n",
    "    plt.figure(figsize=(6,3))\n",
    "    syn_counts = syn[column].value_counts(normalize=True).sort_index()\n",
    "    real_counts = real[column].value_counts(normalize=True).sort_index()\n",
    "    width = 0.35\n",
    "    idx = np.arange(len(syn_counts))\n",
    "    plt.bar(idx-width/2, real_counts.values, width=width, color='skyblue', label='Real')\n",
    "    plt.bar(idx+width/2, syn_counts.values, width=width, color='salmon', label='Synthetic')\n",
    "    plt.xticks(idx, syn_counts.index)\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.title(title or f\"{column}: Real vs Synthetic\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if data_type_choice == '1':\n",
    "    # Continuous columns\n",
    "    for col in ['age', 'systolic_bp', 'diastolic_bp', 'glucose', 'length_of_stay']:\n",
    "        plot_distribution_compare(synthetic_df, real_df, col, title=f\"{col.title()} Distribution: Real vs Synthetic\")\n",
    "    # Categorical columns\n",
    "    for cat in ['sex', 'admission_type', 'discharge_status']:\n",
    "        plot_categorical_compare(synthetic_df, real_df, cat, title=f\"{cat.replace('_',' ').title()}: Real vs Synthetic\")\n",
    "\n",
    "# --- 6. NLP and Statistics for Synthetic Textual Data ---\n",
    "if data_type_choice == '2':\n",
    "    # Simple statistics: length, vocabulary, n-grams (no ML models here, just basic fidelity metrics)\n",
    "    synthetic_df['num_words'] = synthetic_df['note_text'].apply(lambda s: len(s.split()))\n",
    "    synthetic_df['num_chars'] = synthetic_df['note_text'].apply(len)\n",
    "    display(Markdown('#### Statistics of Synthetic Clinical Notes'))\n",
    "    display(synthetic_df[['note_id', 'num_words', 'num_chars']].describe())\n",
    "    # Show text diversity (basic n-gram coverage)\n",
    "    from collections import Counter\n",
    "    all_text = ' '.join(synthetic_df['note_text']).lower().split()\n",
    "    vocab = set(all_text)\n",
    "    word_counts = Counter(all_text)\n",
    "    top_words = word_counts.most_common(10)\n",
    "    display(Markdown(f\"**Vocabulary size:** {len(vocab)}\"))\n",
    "    display(Markdown(f\"**Top 10 most common words:** {', '.join(f'{w} ({c})' for w,c in top_words)}\"))\n",
    "    # Word length histogram\n",
    "    plt.figure(figsize=(5,2.5))\n",
    "    sns.histplot(synthetic_df['num_words'], bins=8, color='orchid', edgecolor='black')\n",
    "    plt.title('Synthetic Note Length (words)')\n",
    "    plt.xlabel('Num words per note')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- 7. Privacy & Utility Discussion (Markdown cell) ---\n",
    "report_md = '''\n",
    "## Utility and Privacy of Generated Synthetic Data\n",
    "\n",
    "- **Utility:**\n",
    "    - Synthetic tabular data imitates real patient distributions and enables rapid prototyping for research, visualization, or algorithmic testing without patient privacy risk.\n",
    "    - The synthetic clinical notes reflect plausible combinations of medical concepts, supporting NLP model testing and iterative prompt engineering.\n",
    "    - Visual comparison demonstrates good alignment in/univariate statistics; for deeper fidelity, advanced methods (e.g. GANs, copulas, or language models) may be considered.\n",
    "\n",
    "- **Privacy:**\n",
    "    - All data is programmatically generated, guaranteeing that no individually-identifying patient information is present.\n",
    "    - Distributional or summary-level attacks are not meaningful (there is no one-to-one mapping with actual patients).\n",
    "    - For deployment in sensitive settings, privacy-preserving approaches (differential privacy, noise injection, output audits) can further strengthen guarantees.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "This notebook supports safe, rapid synthetic healthcare data prototyping, visualization, and model pipeline validation, with explicit separation from true patient data. Researchers should always validate downstream analysis pipelines for generalizability beyond synthetic benchmarks.\n",
    "'''\n",
    "display(Markdown(report_md))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc03d31",
   "metadata": {},
   "source": [
    "Integrated Workflow: Rapid Prototyping Chain of EDA → NLP → Synthetic Data in Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rapid Prototyping: Chained Healthcare AI Workflow (EDA â NLP â Synthetic Data)\n",
    "# \n",
    "# This final cell demonstrates how all prior reusable notebook components can be chained seamlessly for fast, iterative experimentation on healthcare data:\n",
    "# - Start with structured EDA\n",
    "# - Apply clinical NLP (named entity recognition, information extraction)\n",
    "# - Generate and validate synthetic data\n",
    "# \n",
    "# By reusing these modular blocks, teams can accelerate prototyping, support regulatory/privacy reviews, and streamline early-stage biomarker/algorithm explorations.\n",
    "\n",
    "from IPython.display import Markdown, display, HTML\n",
    "\n",
    "# --- 1. Recap: EDA Preview ---\n",
    "display(Markdown(\"## ð© Step 1: EDA â Real Healthcare Data Preview\"))\n",
    "try:\n",
    "    display(health_df.head(5))\n",
    "    display(health_df.describe(include='all'))\n",
    "except Exception:\n",
    "    display(Markdown('_(Structured health_df not found; please rerun EDA cell above if needed.)_'))\n",
    "\n",
    "# --- 2. Recap: Clinical NLP on Example Notes ---\n",
    "display(Markdown(\"## ð© Step 2: NLP â Information Extraction from Clinical Notes\"))\n",
    "try:\n",
    "    display(clinical_notes_df.head(3))\n",
    "    display(Markdown('Named entities (first 3 clinical notes):'))\n",
    "    for idx, row in clinical_notes_df.head(3).iterrows():\n",
    "        ent_list = row['entities'] if 'entities' in row else []\n",
    "        ents_md = []\n",
    "        for ent in ent_list:\n",
    "            label = ent.get('entity_group', ent.get('entity',''))\n",
    "            word = ent.get('word', 'â')\n",
    "            score = ent.get('score', 0.0)\n",
    "            ents_md.append(f\"- <b>{label}</b>: '{word}' <span style=\"color:grey\">({score:.2f})</span>\")\n",
    "        if not ents_md:\n",
    "            ents_md = ['_No entities extracted._']\n",
    "        display(HTML('<br/>'.join(ents_md)))\n",
    "except Exception:\n",
    "    display(Markdown('_(clinical_notes_df not found; please rerun NLP cell above if needed.)_'))\n",
    "\n",
    "# --- 3. Recap: Synthetic Data & Distribution Comparison ---\n",
    "display(Markdown(\"## ð© Step 3: Synthetic Data â Generate & Visualize\"))\n",
    "\n",
    "try:\n",
    "    # Display synthetic tabular data preview (via prior activity's synthetic_df)\n",
    "    display(Markdown('#### Synthetic Patient Records (preview)'))\n",
    "    display(synthetic_df.head(5))\n",
    "    # Comparative distribution plot for numeric feature\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(health_df['age'], color='skyblue', label='Real', kde=True, stat='density', bins=20, alpha=0.4)\n",
    "    sns.histplot(synthetic_df['age'], color='r', label='Synthetic', kde=True, stat='density', bins=20, alpha=0.4)\n",
    "    plt.title('Age: Synthetic vs Real Distributions')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception:\n",
    "    display(Markdown('_Synthetic tabular data not found. To reproduce, rerun the synthetic notebook cells above._'))\n",
    "\n",
    "# --- 4. Workflow Summary & Prototype Value (Markdown) ---\n",
    "summary_md = '''\n",
    "## ð Workflow Summary: Rapid AI Healthcare Experimentation\n",
    "\n",
    "This notebook chains **EDA â Clinical NLP â Synthetic Data Generation** in modular, reusable steps:\n",
    "\n",
    "- **Exploratory Data Analysis:**\n",
    "    - Key dataset properties and plausible statistical distributions are surveyed first, identifying data issues and likely modeling features.\n",
    "- **NLP Pipeline:**\n",
    "    - Transformer-based entity recognition extracts clinical terms from de-identified text; model swaps and tuning are rapid for improved accuracy.\n",
    "- **Synthetic Data Generation:**\n",
    "    - Privacy-compliant, structurally-matched synthetic records are quickly produced and compared distributionally to the original data.\n",
    "\n",
    "**Benefits:**\n",
    "- Dramatically cuts iteration times by allowing quick âplug-and-playâ experimentation.\n",
    "- Supports safe algorithm development and sharing of notebooks.\n",
    "- Every component supports independent reuse/extension for future, more advanced workflows (e.g., federated learning, multimodal fusion).\n",
    "- Integrated visualizations and markdown provide immediate insight at each stage.\n",
    "\n",
    "_This approach enabled chaining three standard healthcare pipelines into a single afternoon workflow, with integrated quality checks, privacy compliance, and easy model switching. Suitable for early-stage discovery, regulatory demos, or preliminary collaborative screening of new ideas._\n",
    "'''\n",
    "display(Markdown(summary_md))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
